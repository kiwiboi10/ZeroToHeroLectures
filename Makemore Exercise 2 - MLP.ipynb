{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df8cdea",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae010e7",
   "metadata": {},
   "source": [
    "Tune the hyperparameters of the training to beat my best validation loss of 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4e578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f8783",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1f12a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9862c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vocabulary of characters and mapping to/from integers\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i + 1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2636b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3]) torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 15],\n",
       "         [ 0, 15, 12],\n",
       "         [15, 12,  9],\n",
       "         [12,  9, 22],\n",
       "         [ 9, 22,  9],\n",
       "         [22,  9,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1, 22],\n",
       "         [ 1, 22,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_dataset(words, context_size = 3):\n",
    "    \n",
    "    X, Y = [], []\n",
    "\n",
    "    for word in words:\n",
    "        context = [0] * context_size\n",
    "        for ch in word + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            \n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    return X, Y\n",
    "        \n",
    "build_dataset(words[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391619cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c568c725",
   "metadata": {},
   "source": [
    "### Creating a Multilayer Perceptron (MLP) Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2113c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(\n",
    "        self, \n",
    "        emb_dim_1,\n",
    "        emb_dim_2,\n",
    "        l1_out_features,\n",
    "        l2_out_features,\n",
    "        num_epochs, \n",
    "        learning_rate, \n",
    "        block_size=3, \n",
    "        minibatch_size=64,\n",
    "        lr_update=20,\n",
    "        lr_decay_factor=0.5,\n",
    "        seed=2147483647\n",
    "    ):\n",
    "        # Store hyperparameters\n",
    "        self.emb_dim_1 = emb_dim_1\n",
    "        self.emb_dim_2 = emb_dim_2\n",
    "        self.l1_out_features = l1_out_features\n",
    "        self.l2_out_features = l2_out_features\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.block_size = block_size\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.lr_update = lr_update\n",
    "        self.lr_decay_factor = lr_decay_factor\n",
    "        self.seed = seed\n",
    "\n",
    "        # Initialize weights with reproducibility\n",
    "        generator = torch.Generator().manual_seed(self.seed)\n",
    "        self.C = torch.randn((self.emb_dim_1, self.emb_dim_2), generator=generator)\n",
    "        self.W1 = torch.randn((self.block_size * self.emb_dim_2, self.l1_out_features), generator=generator)\n",
    "        self.b1 = torch.randn(self.l1_out_features, generator=generator)\n",
    "        self.W2 = torch.randn((self.l1_out_features, self.l2_out_features), generator=generator)\n",
    "        self.b2 = torch.randn(self.l2_out_features, generator=generator)\n",
    "\n",
    "        # Gather parameters and enable gradients\n",
    "        self.parameters = [self.C, self.W1, self.b1, self.W2, self.b2]\n",
    "        self.num_params = sum(p.nelement() for p in self.parameters)\n",
    "        for p in self.parameters:\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        # Get embeddings for input indices\n",
    "        embeddings = self.C[x]  # shape: (batch, context_size, emb_dim_2)\n",
    "        # Flatten the context\n",
    "        layer1_in = embeddings.view(embeddings.shape[0], -1)\n",
    "        # Hidden layer with tanh activation\n",
    "        layer1_out = torch.tanh(layer1_in @ self.W1 + self.b1)\n",
    "        # Compute logits and cross-entropy loss\n",
    "        logits = layer1_out @ self.W2 + self.b2\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.history = {}\n",
    "        best_loss = math.inf\n",
    "        counter = 0\n",
    "        min_lr = 1e-6\n",
    "\n",
    "        for k in range(self.num_epochs):\n",
    "            # Sample a minibatch\n",
    "            ix = torch.randint(0, x.shape[0], (self.minibatch_size,))\n",
    "            loss = self(x[ix], y[ix])\n",
    "            self.history[f\"epoch_{k+1}\"] = [loss.item(), self.learning_rate]\n",
    "\n",
    "            # Update best loss and counter for learning rate decay\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "\n",
    "            # Reset gradients\n",
    "            for p in self.parameters:\n",
    "                p.grad = None\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Decay learning rate if no improvement for 'lr_update' epochs\n",
    "            if counter >= self.lr_update and self.learning_rate > min_lr:\n",
    "                self.learning_rate *= self.lr_decay_factor\n",
    "                counter = 0\n",
    "\n",
    "            # Update parameters inside a no_grad block\n",
    "            with torch.no_grad():\n",
    "                for p in self.parameters:\n",
    "                    p -= self.learning_rate * p.grad\n",
    "\n",
    "        return self.history\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        with torch.no_grad():\n",
    "            loss = self(x, y)\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(\n",
    "    emb_dim_1=27,\n",
    "    emb_dim_2=10,\n",
    "    l1_out_features=200, \n",
    "    l2_out_features=27,\n",
    "    num_epochs=100000,\n",
    "    learning_rate=0.1,\n",
    "    minibatch_size=64,\n",
    "    lr_update=5000,\n",
    "    lr_decay_factor=0.5,\n",
    "    seed=2147483647\n",
    ")\n",
    "\n",
    "print(\"Training started...\")\n",
    "history = mlp_model.fit(Xtr, Ytr)\n",
    "print(history)\n",
    "\n",
    "train_loss = mlp_model.evaluate(Xtr, Ytr)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "# --- Evaluate on the Validation Set ---\n",
    "val_loss = mlp_model.evaluate(Xdev, Ydev)\n",
    "print(\"Validation Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bf929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
